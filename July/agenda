Next order of business:
-Repeat in Q&A format and classification task
-Repeat WoMan.py but for word manifolds (instead of final token)
-Repeat last token work with interpolation between manifold centroids and same for word manifolds
-Try perturbing in directions orthogonal to the manifold (see if this corresponds to robustness or some dense feature)
-Try ablating PCs of the manifold (i.e. drop a dimension)

Papers: train meta-meta-SAE on same data as Nanda paper; see if you keep getting more atomic features

Speculative: What happens when you prompt an LLM during inference to learn a new language of your syntactical design? How are the components of this synthetic simple language represented?
    Or, simpler, how differently are languages represented? Is it just some orthogonal vector indicating language or does syntax mess up more?